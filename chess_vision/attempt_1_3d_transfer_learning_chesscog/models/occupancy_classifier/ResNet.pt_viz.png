digraph {
	graph [size="59.55,59.55"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	13019225664 [label="
 (1, 2)" fillcolor=darkolivegreen1]
	13019380464 [label=AddmmBackward0]
	13019379696 -> 13019380464
	13019495648 [label="model.fc.bias
 (2)" fillcolor=lightblue]
	13019495648 -> 13019379696
	13019379696 [label=AccumulateGrad]
	13019380032 -> 13019380464
	13019380032 [label=ViewBackward0]
	13019380128 -> 13019380032
	13019380128 [label=MeanBackward1]
	13019379408 -> 13019380128
	13019379408 [label=ReluBackward0]
	13019379216 -> 13019379408
	13019379216 [label=AddBackward0]
	13019378976 -> 13019379216
	13019378976 [label=NativeBatchNormBackward0]
	13019378688 -> 13019378976
	13019378688 [label=ConvolutionBackward0]
	13019378256 -> 13019378688
	13019378256 [label=ReluBackward0]
	13019377968 -> 13019378256
	13019377968 [label=NativeBatchNormBackward0]
	13019377728 -> 13019377968
	13019377728 [label=ConvolutionBackward0]
	13019379120 -> 13019377728
	13019379120 [label=ReluBackward0]
	13019377104 -> 13019379120
	13019377104 [label=AddBackward0]
	13019376912 -> 13019377104
	13019376912 [label=NativeBatchNormBackward0]
	13019376624 -> 13019376912
	13019376624 [label=ConvolutionBackward0]
	13019376192 -> 13019376624
	13019376192 [label=ReluBackward0]
	13019375856 -> 13019376192
	13019375856 [label=NativeBatchNormBackward0]
	13019375664 -> 13019375856
	13019375664 [label=ConvolutionBackward0]
	13019375232 -> 13019375664
	13019375232 [label=ReluBackward0]
	13019374944 -> 13019375232
	13019374944 [label=AddBackward0]
	13019374704 -> 13019374944
	13019374704 [label=NativeBatchNormBackward0]
	13019374416 -> 13019374704
	13019374416 [label=ConvolutionBackward0]
	13019373984 -> 13019374416
	13019373984 [label=ReluBackward0]
	13019373696 -> 13019373984
	13019373696 [label=NativeBatchNormBackward0]
	13019373360 -> 13019373696
	13019373360 [label=ConvolutionBackward0]
	13019374800 -> 13019373360
	13019374800 [label=ReluBackward0]
	13019372784 -> 13019374800
	13019372784 [label=AddBackward0]
	13019372544 -> 13019372784
	13019372544 [label=NativeBatchNormBackward0]
	13019372208 -> 13019372544
	13019372208 [label=ConvolutionBackward0]
	13019371824 -> 13019372208
	13019371824 [label=ReluBackward0]
	13019371536 -> 13019371824
	13019371536 [label=NativeBatchNormBackward0]
	13019371296 -> 13019371536
	13019371296 [label=ConvolutionBackward0]
	13019370864 -> 13019371296
	13019370864 [label=ReluBackward0]
	13019370576 -> 13019370864
	13019370576 [label=AddBackward0]
	13019370384 -> 13019370576
	13019370384 [label=NativeBatchNormBackward0]
	13019370048 -> 13019370384
	13019370048 [label=ConvolutionBackward0]
	13019369616 -> 13019370048
	13019369616 [label=ReluBackward0]
	13019369328 -> 13019369616
	13019369328 [label=NativeBatchNormBackward0]
	13019369136 -> 13019369328
	13019369136 [label=ConvolutionBackward0]
	13019370480 -> 13019369136
	13019370480 [label=ReluBackward0]
	13019368464 -> 13019370480
	13019368464 [label=AddBackward0]
	13019368272 -> 13019368464
	13019368272 [label=NativeBatchNormBackward0]
	13019367984 -> 13019368272
	13019367984 [label=ConvolutionBackward0]
	13019367552 -> 13019367984
	13019367552 [label=ReluBackward0]
	13019367120 -> 13019367552
	13019367120 [label=NativeBatchNormBackward0]
	13019366928 -> 13019367120
	13019366928 [label=ConvolutionBackward0]
	13019366544 -> 13019366928
	13019366544 [label=ReluBackward0]
	13019366208 -> 13019366544
	13019366208 [label=AddBackward0]
	13019366016 -> 13019366208
	13019366016 [label=NativeBatchNormBackward0]
	13019365680 -> 13019366016
	13019365680 [label=ConvolutionBackward0]
	13019365488 -> 13019365680
	13019365488 [label=ReluBackward0]
	13019136832 -> 13019365488
	13019136832 [label=NativeBatchNormBackward0]
	13019137888 -> 13019136832
	13019137888 [label=ConvolutionBackward0]
	13019366112 -> 13019137888
	13019366112 [label=ReluBackward0]
	13019145664 -> 13019366112
	13019145664 [label=AddBackward0]
	13019151184 -> 13019145664
	13019151184 [label=NativeBatchNormBackward0]
	13019150608 -> 13019151184
	13019150608 [label=ConvolutionBackward0]
	13019151232 -> 13019150608
	13019151232 [label=ReluBackward0]
	13019151616 -> 13019151232
	13019151616 [label=NativeBatchNormBackward0]
	13019151328 -> 13019151616
	13019151328 [label=ConvolutionBackward0]
	13019146432 -> 13019151328
	13019146432 [label=MaxPool2DWithIndicesBackward0]
	13019148160 -> 13019146432
	13019148160 [label=ReluBackward0]
	13019149024 -> 13019148160
	13019149024 [label=NativeBatchNormBackward0]
	13019150032 -> 13019149024
	13019150032 [label=ConvolutionBackward0]
	13019149504 -> 13019150032
	13019219824 [label="model.conv1.weight
 (64, 3, 7, 7)" fillcolor=lightblue]
	13019219824 -> 13019149504
	13019149504 [label=AccumulateGrad]
	13019150320 -> 13019149024
	13019219984 [label="model.bn1.weight
 (64)" fillcolor=lightblue]
	13019219984 -> 13019150320
	13019150320 [label=AccumulateGrad]
	13019150128 -> 13019149024
	13019219184 [label="model.bn1.bias
 (64)" fillcolor=lightblue]
	13019219184 -> 13019150128
	13019150128 [label=AccumulateGrad]
	13019149840 -> 13019151328
	13019222464 [label="model.layer1.0.conv1.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	13019222464 -> 13019149840
	13019149840 [label=AccumulateGrad]
	13019150896 -> 13019151616
	13019223104 [label="model.layer1.0.bn1.weight
 (64)" fillcolor=lightblue]
	13019223104 -> 13019150896
	13019150896 [label=AccumulateGrad]
	13019151808 -> 13019151616
	13019223184 [label="model.layer1.0.bn1.bias
 (64)" fillcolor=lightblue]
	13019223184 -> 13019151808
	13019151808 [label=AccumulateGrad]
	13019151904 -> 13019150608
	13019224864 [label="model.layer1.0.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	13019224864 -> 13019151904
	13019151904 [label=AccumulateGrad]
	13019152240 -> 13019151184
	13019225424 [label="model.layer1.0.bn2.weight
 (64)" fillcolor=lightblue]
	13019225424 -> 13019152240
	13019152240 [label=AccumulateGrad]
	13019151952 -> 13019151184
	13019220544 [label="model.layer1.0.bn2.bias
 (64)" fillcolor=lightblue]
	13019220544 -> 13019151952
	13019151952 [label=AccumulateGrad]
	13019146432 -> 13019145664
	13019138368 -> 13019137888
	13019227424 [label="model.layer1.1.conv1.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	13019227424 -> 13019138368
	13019138368 [label=AccumulateGrad]
	13019137312 -> 13019136832
	13019228064 [label="model.layer1.1.bn1.weight
 (64)" fillcolor=lightblue]
	13019228064 -> 13019137312
	13019137312 [label=AccumulateGrad]
	13019137696 -> 13019136832
	13019228144 [label="model.layer1.1.bn1.bias
 (64)" fillcolor=lightblue]
	13019228144 -> 13019137696
	13019137696 [label=AccumulateGrad]
	13019365440 -> 13019365680
	13019229744 [label="model.layer1.1.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	13019229744 -> 13019365440
	13019365440 [label=AccumulateGrad]
	13019365776 -> 13019366016
	13019230464 [label="model.layer1.1.bn2.weight
 (64)" fillcolor=lightblue]
	13019230464 -> 13019365776
	13019365776 [label=AccumulateGrad]
	13019365872 -> 13019366016
	13019230544 [label="model.layer1.1.bn2.bias
 (64)" fillcolor=lightblue]
	13019230544 -> 13019365872
	13019365872 [label=AccumulateGrad]
	13019366112 -> 13019366208
	13019366640 -> 13019366928
	13019232144 [label="model.layer2.0.conv1.weight
 (128, 64, 3, 3)" fillcolor=lightblue]
	13019232144 -> 13019366640
	13019366640 [label=AccumulateGrad]
	13019367024 -> 13019367120
	13019232624 [label="model.layer2.0.bn1.weight
 (128)" fillcolor=lightblue]
	13019232624 -> 13019367024
	13019367024 [label=AccumulateGrad]
	13019367456 -> 13019367120
	13019233024 [label="model.layer2.0.bn1.bias
 (128)" fillcolor=lightblue]
	13019233024 -> 13019367456
	13019367456 [label=AccumulateGrad]
	13019367648 -> 13019367984
	13019398368 [label="model.layer2.0.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	13019398368 -> 13019367648
	13019367648 [label=AccumulateGrad]
	13019368080 -> 13019368272
	13019398928 [label="model.layer2.0.bn2.weight
 (128)" fillcolor=lightblue]
	13019398928 -> 13019368080
	13019368080 [label=AccumulateGrad]
	13019368176 -> 13019368272
	13019399328 [label="model.layer2.0.bn2.bias
 (128)" fillcolor=lightblue]
	13019399328 -> 13019368176
	13019368176 [label=AccumulateGrad]
	13019368368 -> 13019368464
	13019368368 [label=NativeBatchNormBackward0]
	13019366736 -> 13019368368
	13019366736 [label=ConvolutionBackward0]
	13019366544 -> 13019366736
	13019366448 -> 13019366736
	13019400768 [label="model.layer2.0.downsample.0.weight
 (128, 64, 1, 1)" fillcolor=lightblue]
	13019400768 -> 13019366448
	13019366448 [label=AccumulateGrad]
	13019367792 -> 13019368368
	13019401328 [label="model.layer2.0.downsample.1.weight
 (128)" fillcolor=lightblue]
	13019401328 -> 13019367792
	13019367792 [label=AccumulateGrad]
	13019367888 -> 13019368368
	13019401728 [label="model.layer2.0.downsample.1.bias
 (128)" fillcolor=lightblue]
	13019401728 -> 13019367888
	13019367888 [label=AccumulateGrad]
	13019368704 -> 13019369136
	13019403168 [label="model.layer2.1.conv1.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	13019403168 -> 13019368704
	13019368704 [label=AccumulateGrad]
	13019369232 -> 13019369328
	13019403728 [label="model.layer2.1.bn1.weight
 (128)" fillcolor=lightblue]
	13019403728 -> 13019369232
	13019369232 [label=AccumulateGrad]
	13019369520 -> 13019369328
	13019404128 [label="model.layer2.1.bn1.bias
 (128)" fillcolor=lightblue]
	13019404128 -> 13019369520
	13019369520 [label=AccumulateGrad]
	13019369712 -> 13019370048
	13019405408 [label="model.layer2.1.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	13019405408 -> 13019369712
	13019369712 [label=AccumulateGrad]
	13019370144 -> 13019370384
	13019405968 [label="model.layer2.1.bn2.weight
 (128)" fillcolor=lightblue]
	13019405968 -> 13019370144
	13019370144 [label=AccumulateGrad]
	13019370288 -> 13019370384
	13019406368 [label="model.layer2.1.bn2.bias
 (128)" fillcolor=lightblue]
	13019406368 -> 13019370288
	13019370288 [label=AccumulateGrad]
	13019370480 -> 13019370576
	13019370960 -> 13019371296
	13019407728 [label="model.layer3.0.conv1.weight
 (256, 128, 3, 3)" fillcolor=lightblue]
	13019407728 -> 13019370960
	13019370960 [label=AccumulateGrad]
	13019371392 -> 13019371536
	13019408208 [label="model.layer3.0.bn1.weight
 (256)" fillcolor=lightblue]
	13019408208 -> 13019371392
	13019371392 [label=AccumulateGrad]
	13019371728 -> 13019371536
	13019408608 [label="model.layer3.0.bn1.bias
 (256)" fillcolor=lightblue]
	13019408608 -> 13019371728
	13019371728 [label=AccumulateGrad]
	13019371920 -> 13019372208
	13019409968 [label="model.layer3.0.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	13019409968 -> 13019371920
	13019371920 [label=AccumulateGrad]
	13019372352 -> 13019372544
	13019410528 [label="model.layer3.0.bn2.weight
 (256)" fillcolor=lightblue]
	13019410528 -> 13019372352
	13019372352 [label=AccumulateGrad]
	13019372448 -> 13019372544
	13019410848 [label="model.layer3.0.bn2.bias
 (256)" fillcolor=lightblue]
	13019410848 -> 13019372448
	13019372448 [label=AccumulateGrad]
	13019372640 -> 13019372784
	13019372640 [label=NativeBatchNormBackward0]
	13019371104 -> 13019372640
	13019371104 [label=ConvolutionBackward0]
	13019370864 -> 13019371104
	13019370768 -> 13019371104
	13019412288 [label="model.layer3.0.downsample.0.weight
 (256, 128, 1, 1)" fillcolor=lightblue]
	13019412288 -> 13019370768
	13019370768 [label=AccumulateGrad]
	13019372016 -> 13019372640
	13019412848 [label="model.layer3.0.downsample.1.weight
 (256)" fillcolor=lightblue]
	13019412848 -> 13019372016
	13019372016 [label=AccumulateGrad]
	13019372112 -> 13019372640
	13019413248 [label="model.layer3.0.downsample.1.bias
 (256)" fillcolor=lightblue]
	13019413248 -> 13019372112
	13019372112 [label=AccumulateGrad]
	13019372976 -> 13019373360
	13019480208 [label="model.layer3.1.conv1.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	13019480208 -> 13019372976
	13019372976 [label=AccumulateGrad]
	13019373456 -> 13019373696
	13019480688 [label="model.layer3.1.bn1.weight
 (256)" fillcolor=lightblue]
	13019480688 -> 13019373456
	13019373456 [label=AccumulateGrad]
	13019373888 -> 13019373696
	13019481088 [label="model.layer3.1.bn1.bias
 (256)" fillcolor=lightblue]
	13019481088 -> 13019373888
	13019373888 [label=AccumulateGrad]
	13019374128 -> 13019374416
	13019482448 [label="model.layer3.1.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	13019482448 -> 13019374128
	13019374128 [label=AccumulateGrad]
	13019374512 -> 13019374704
	13019482928 [label="model.layer3.1.bn2.weight
 (256)" fillcolor=lightblue]
	13019482928 -> 13019374512
	13019374512 [label=AccumulateGrad]
	13019374608 -> 13019374704
	13019483328 [label="model.layer3.1.bn2.bias
 (256)" fillcolor=lightblue]
	13019483328 -> 13019374608
	13019374608 [label=AccumulateGrad]
	13019374800 -> 13019374944
	13019375376 -> 13019375664
	13019484528 [label="model.layer4.0.conv1.weight
 (512, 256, 3, 3)" fillcolor=lightblue]
	13019484528 -> 13019375376
	13019375376 [label=AccumulateGrad]
	13019375760 -> 13019375856
	13019485088 [label="model.layer4.0.bn1.weight
 (512)" fillcolor=lightblue]
	13019485088 -> 13019375760
	13019375760 [label=AccumulateGrad]
	13019376048 -> 13019375856
	13019485408 [label="model.layer4.0.bn1.bias
 (512)" fillcolor=lightblue]
	13019485408 -> 13019376048
	13019376048 [label=AccumulateGrad]
	13019376288 -> 13019376624
	13019486608 [label="model.layer4.0.conv2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	13019486608 -> 13019376288
	13019376288 [label=AccumulateGrad]
	13019376720 -> 13019376912
	13019487168 [label="model.layer4.0.bn2.weight
 (512)" fillcolor=lightblue]
	13019487168 -> 13019376720
	13019376720 [label=AccumulateGrad]
	13019376816 -> 13019376912
	13019487568 [label="model.layer4.0.bn2.bias
 (512)" fillcolor=lightblue]
	13019487568 -> 13019376816
	13019376816 [label=AccumulateGrad]
	13019377008 -> 13019377104
	13019377008 [label=NativeBatchNormBackward0]
	13019375472 -> 13019377008
	13019375472 [label=ConvolutionBackward0]
	13019375232 -> 13019375472
	13019375136 -> 13019375472
	13019488768 [label="model.layer4.0.downsample.0.weight
 (512, 256, 1, 1)" fillcolor=lightblue]
	13019488768 -> 13019375136
	13019375136 [label=AccumulateGrad]
	13019376384 -> 13019377008
	13019489328 [label="model.layer4.0.downsample.1.weight
 (512)" fillcolor=lightblue]
	13019489328 -> 13019376384
	13019376384 [label=AccumulateGrad]
	13019376480 -> 13019377008
	13019489648 [label="model.layer4.0.downsample.1.bias
 (512)" fillcolor=lightblue]
	13019489648 -> 13019376480
	13019376480 [label=AccumulateGrad]
	13019377296 -> 13019377728
	13019491008 [label="model.layer4.1.conv1.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	13019491008 -> 13019377296
	13019377296 [label=AccumulateGrad]
	13019377872 -> 13019377968
	13019491568 [label="model.layer4.1.bn1.weight
 (512)" fillcolor=lightblue]
	13019491568 -> 13019377872
	13019377872 [label=AccumulateGrad]
	13019378160 -> 13019377968
	13019491888 [label="model.layer4.1.bn1.bias
 (512)" fillcolor=lightblue]
	13019491888 -> 13019378160
	13019378160 [label=AccumulateGrad]
	13019378352 -> 13019378688
	13019493168 [label="model.layer4.1.conv2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	13019493168 -> 13019378352
	13019378352 [label=AccumulateGrad]
	13019378784 -> 13019378976
	13019493648 [label="model.layer4.1.bn2.weight
 (512)" fillcolor=lightblue]
	13019493648 -> 13019378784
	13019378784 [label=AccumulateGrad]
	13019378880 -> 13019378976
	13019494048 [label="model.layer4.1.bn2.bias
 (512)" fillcolor=lightblue]
	13019494048 -> 13019378880
	13019378880 [label=AccumulateGrad]
	13019379120 -> 13019379216
	13019379792 -> 13019380464
	13019379792 [label=TBackward0]
	13019379312 -> 13019379792
	13019495248 [label="model.fc.weight
 (2, 512)" fillcolor=lightblue]
	13019495248 -> 13019379312
	13019379312 [label=AccumulateGrad]
	13019380464 -> 13019225664
}
