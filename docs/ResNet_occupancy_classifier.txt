digraph {
	graph [size="59.55,59.55"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	13582911344 [label="
 (1, 2)" fillcolor=darkolivegreen1]
	13582957776 [label=AddmmBackward0]
	13582957152 -> 13582957776
	13583194912 [label="model.fc.bias
 (2)" fillcolor=lightblue]
	13583194912 -> 13582957152
	13582957152 [label=AccumulateGrad]
	13582957392 -> 13582957776
	13582957392 [label=ViewBackward0]
	13582957488 -> 13582957392
	13582957488 [label=MeanBackward1]
	13582956864 -> 13582957488
	13582956864 [label=ReluBackward0]
	13582956624 -> 13582956864
	13582956624 [label=AddBackward0]
	13582956432 -> 13582956624
	13582956432 [label=NativeBatchNormBackward0]
	13582956144 -> 13582956432
	13582956144 [label=ConvolutionBackward0]
	13582955712 -> 13582956144
	13582955712 [label=ReluBackward0]
	13582955376 -> 13582955712
	13582955376 [label=NativeBatchNormBackward0]
	13582955184 -> 13582955376
	13582955184 [label=ConvolutionBackward0]
	13582956528 -> 13582955184
	13582956528 [label=ReluBackward0]
	13582954560 -> 13582956528
	13582954560 [label=AddBackward0]
	13582954368 -> 13582954560
	13582954368 [label=NativeBatchNormBackward0]
	13582954032 -> 13582954368
	13582954032 [label=ConvolutionBackward0]
	13582953648 -> 13582954032
	13582953648 [label=ReluBackward0]
	13582953312 -> 13582953648
	13582953312 [label=NativeBatchNormBackward0]
	13582953120 -> 13582953312
	13582953120 [label=ConvolutionBackward0]
	13582952688 -> 13582953120
	13582952688 [label=ReluBackward0]
	13582952400 -> 13582952688
	13582952400 [label=AddBackward0]
	13582952160 -> 13582952400
	13582952160 [label=NativeBatchNormBackward0]
	13582951872 -> 13582952160
	13582951872 [label=ConvolutionBackward0]
	13582951344 -> 13582951872
	13582951344 [label=ReluBackward0]
	13582951056 -> 13582951344
	13582951056 [label=NativeBatchNormBackward0]
	13582950816 -> 13582951056
	13582950816 [label=ConvolutionBackward0]
	13582952304 -> 13582950816
	13582952304 [label=ReluBackward0]
	13582950192 -> 13582952304
	13582950192 [label=AddBackward0]
	13582950000 -> 13582950192
	13582950000 [label=NativeBatchNormBackward0]
	13582949712 -> 13582950000
	13582949712 [label=ConvolutionBackward0]
	13582949280 -> 13582949712
	13582949280 [label=ReluBackward0]
	13582948944 -> 13582949280
	13582948944 [label=NativeBatchNormBackward0]
	13582948752 -> 13582948944
	13582948752 [label=ConvolutionBackward0]
	13582948320 -> 13582948752
	13582948320 [label=ReluBackward0]
	13582948032 -> 13582948320
	13582948032 [label=AddBackward0]
	13582947792 -> 13582948032
	13582947792 [label=NativeBatchNormBackward0]
	13582947504 -> 13582947792
	13582947504 [label=ConvolutionBackward0]
	13582946928 -> 13582947504
	13582946928 [label=ReluBackward0]
	13582947168 -> 13582946928
	13582947168 [label=NativeBatchNormBackward0]
	13582946304 -> 13582947168
	13582946304 [label=ConvolutionBackward0]
	13582947888 -> 13582946304
	13582947888 [label=ReluBackward0]
	13582946208 -> 13582947888
	13582946208 [label=AddBackward0]
	13582944672 -> 13582946208
	13582944672 [label=NativeBatchNormBackward0]
	13582945104 -> 13582944672
	13582945104 [label=ConvolutionBackward0]
	13582944192 -> 13582945104
	13582944192 [label=ReluBackward0]
	13582944816 -> 13582944192
	13582944816 [label=NativeBatchNormBackward0]
	13582944432 -> 13582944816
	13582944432 [label=ConvolutionBackward0]
	13582943712 -> 13582944432
	13582943712 [label=ReluBackward0]
	13582943952 -> 13582943712
	13582943952 [label=AddBackward0]
	13582943760 -> 13582943952
	13582943760 [label=NativeBatchNormBackward0]
	13582943328 -> 13582943760
	13582943328 [label=ConvolutionBackward0]
	13582942512 -> 13582943328
	13582942512 [label=ReluBackward0]
	13582944768 -> 13582942512
	13582944768 [label=NativeBatchNormBackward0]
	13582942320 -> 13582944768
	13582942320 [label=ConvolutionBackward0]
	13582943232 -> 13582942320
	13582943232 [label=ReluBackward0]
	13582759776 -> 13582943232
	13582759776 [label=AddBackward0]
	13582760688 -> 13582759776
	13582760688 [label=NativeBatchNormBackward0]
	13582755984 -> 13582760688
	13582755984 [label=ConvolutionBackward0]
	13582751664 -> 13582755984
	13582751664 [label=ReluBackward0]
	13582751760 -> 13582751664
	13582751760 [label=NativeBatchNormBackward0]
	13582751616 -> 13582751760
	13582751616 [label=ConvolutionBackward0]
	13582761456 -> 13582751616
	13582761456 [label=MaxPool2DWithIndicesBackward0]
	13582750032 -> 13582761456
	13582750032 [label=ReluBackward0]
	13582756944 -> 13582750032
	13582756944 [label=NativeBatchNormBackward0]
	13582756992 -> 13582756944
	13582756992 [label=ConvolutionBackward0]
	13582759392 -> 13582756992
	13582804736 [label="model.conv1.weight
 (64, 3, 7, 7)" fillcolor=lightblue]
	13582804736 -> 13582759392
	13582759392 [label=AccumulateGrad]
	13582756896 -> 13582756944
	13582810496 [label="model.bn1.weight
 (64)" fillcolor=lightblue]
	13582810496 -> 13582756896
	13582756896 [label=AccumulateGrad]
	13582749792 -> 13582756944
	13582805216 [label="model.bn1.bias
 (64)" fillcolor=lightblue]
	13582805216 -> 13582749792
	13582749792 [label=AccumulateGrad]
	13582758192 -> 13582751616
	13582807136 [label="model.layer1.0.conv1.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	13582807136 -> 13582758192
	13582758192 [label=AccumulateGrad]
	13582748592 -> 13582751760
	13582808496 [label="model.layer1.0.bn1.weight
 (64)" fillcolor=lightblue]
	13582808496 -> 13582748592
	13582748592 [label=AccumulateGrad]
	13582760208 -> 13582751760
	13582810096 [label="model.layer1.0.bn1.bias
 (64)" fillcolor=lightblue]
	13582810096 -> 13582760208
	13582760208 [label=AccumulateGrad]
	13582749744 -> 13582755984
	13582810416 [label="model.layer1.0.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	13582810416 -> 13582749744
	13582749744 [label=AccumulateGrad]
	13582760256 -> 13582760688
	13582810256 [label="model.layer1.0.bn2.weight
 (64)" fillcolor=lightblue]
	13582810256 -> 13582760256
	13582760256 [label=AccumulateGrad]
	13582761840 -> 13582760688
	13582810896 [label="model.layer1.0.bn2.bias
 (64)" fillcolor=lightblue]
	13582810896 -> 13582761840
	13582761840 [label=AccumulateGrad]
	13582761456 -> 13582759776
	13582946976 -> 13582942320
	13582910624 [label="model.layer1.1.conv1.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	13582910624 -> 13582946976
	13582946976 [label=AccumulateGrad]
	13582942464 -> 13582944768
	13582909984 [label="model.layer1.1.bn1.weight
 (64)" fillcolor=lightblue]
	13582909984 -> 13582942464
	13582942464 [label=AccumulateGrad]
	13582942896 -> 13582944768
	13582911264 [label="model.layer1.1.bn1.bias
 (64)" fillcolor=lightblue]
	13582911264 -> 13582942896
	13582942896 [label=AccumulateGrad]
	13582942656 -> 13582943328
	13582913344 [label="model.layer1.1.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	13582913344 -> 13582942656
	13582942656 [label=AccumulateGrad]
	13582942992 -> 13582943760
	13582913744 [label="model.layer1.1.bn2.weight
 (64)" fillcolor=lightblue]
	13582913744 -> 13582942992
	13582942992 [label=AccumulateGrad]
	13582944384 -> 13582943760
	13582914304 [label="model.layer1.1.bn2.bias
 (64)" fillcolor=lightblue]
	13582914304 -> 13582944384
	13582944384 [label=AccumulateGrad]
	13582943232 -> 13582943952
	13582944240 -> 13582944432
	13582914944 [label="model.layer2.0.conv1.weight
 (128, 64, 3, 3)" fillcolor=lightblue]
	13582914944 -> 13582944240
	13582944240 [label=AccumulateGrad]
	13582944720 -> 13582944816
	13582915664 [label="model.layer2.0.bn1.weight
 (128)" fillcolor=lightblue]
	13582915664 -> 13582944720
	13582944720 [label=AccumulateGrad]
	13582945152 -> 13582944816
	13582911984 [label="model.layer2.0.bn1.bias
 (128)" fillcolor=lightblue]
	13582911984 -> 13582945152
	13582945152 [label=AccumulateGrad]
	13582945344 -> 13582945104
	13582917504 [label="model.layer2.0.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	13582917504 -> 13582945344
	13582945344 [label=AccumulateGrad]
	13582945296 -> 13582944672
	13582918064 [label="model.layer2.0.bn2.weight
 (128)" fillcolor=lightblue]
	13582918064 -> 13582945296
	13582945296 [label=AccumulateGrad]
	13582945968 -> 13582944672
	13582918464 [label="model.layer2.0.bn2.bias
 (128)" fillcolor=lightblue]
	13582918464 -> 13582945968
	13582945968 [label=AccumulateGrad]
	13582946160 -> 13582946208
	13582946160 [label=NativeBatchNormBackward0]
	13582943904 -> 13582946160
	13582943904 [label=ConvolutionBackward0]
	13582943712 -> 13582943904
	13582944048 -> 13582943904
	13582919744 [label="model.layer2.0.downsample.0.weight
 (128, 64, 1, 1)" fillcolor=lightblue]
	13582919744 -> 13582944048
	13582944048 [label=AccumulateGrad]
	13582945056 -> 13582946160
	13582920304 [label="model.layer2.0.downsample.1.weight
 (128)" fillcolor=lightblue]
	13582920304 -> 13582945056
	13582945056 [label=AccumulateGrad]
	13582945440 -> 13582946160
	13582920704 [label="model.layer2.0.downsample.1.bias
 (128)" fillcolor=lightblue]
	13582920704 -> 13582945440
	13582945440 [label=AccumulateGrad]
	13582946400 -> 13582946304
	13582922064 [label="model.layer2.1.conv1.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	13582922064 -> 13582946400
	13582946400 [label=AccumulateGrad]
	13582945728 -> 13582947168
	13582922624 [label="model.layer2.1.bn1.weight
 (128)" fillcolor=lightblue]
	13582922624 -> 13582945728
	13582945728 [label=AccumulateGrad]
	13582942560 -> 13582947168
	13582923024 [label="model.layer2.1.bn1.bias
 (128)" fillcolor=lightblue]
	13582923024 -> 13582942560
	13582942560 [label=AccumulateGrad]
	13582947312 -> 13582947504
	13582924384 [label="model.layer2.1.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	13582924384 -> 13582947312
	13582947312 [label=AccumulateGrad]
	13582947600 -> 13582947792
	13582924864 [label="model.layer2.1.bn2.weight
 (128)" fillcolor=lightblue]
	13582924864 -> 13582947600
	13582947600 [label=AccumulateGrad]
	13582947696 -> 13582947792
	13582925264 [label="model.layer2.1.bn2.bias
 (128)" fillcolor=lightblue]
	13582925264 -> 13582947696
	13582947696 [label=AccumulateGrad]
	13582947888 -> 13582948032
	13582948464 -> 13582948752
	13583057760 [label="model.layer3.0.conv1.weight
 (256, 128, 3, 3)" fillcolor=lightblue]
	13583057760 -> 13582948464
	13582948464 [label=AccumulateGrad]
	13582948848 -> 13582948944
	13583058240 [label="model.layer3.0.bn1.weight
 (256)" fillcolor=lightblue]
	13583058240 -> 13582948848
	13582948848 [label=AccumulateGrad]
	13582949136 -> 13582948944
	13583058560 [label="model.layer3.0.bn1.bias
 (256)" fillcolor=lightblue]
	13583058560 -> 13582949136
	13582949136 [label=AccumulateGrad]
	13582949376 -> 13582949712
	13583059920 [label="model.layer3.0.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	13583059920 -> 13582949376
	13582949376 [label=AccumulateGrad]
	13582949808 -> 13582950000
	13583060480 [label="model.layer3.0.bn2.weight
 (256)" fillcolor=lightblue]
	13583060480 -> 13582949808
	13582949808 [label=AccumulateGrad]
	13582949904 -> 13582950000
	13583060880 [label="model.layer3.0.bn2.bias
 (256)" fillcolor=lightblue]
	13583060880 -> 13582949904
	13582949904 [label=AccumulateGrad]
	13582950096 -> 13582950192
	13582950096 [label=NativeBatchNormBackward0]
	13582948560 -> 13582950096
	13582948560 [label=ConvolutionBackward0]
	13582948320 -> 13582948560
	13582948224 -> 13582948560
	13583062000 [label="model.layer3.0.downsample.0.weight
 (256, 128, 1, 1)" fillcolor=lightblue]
	13583062000 -> 13582948224
	13582948224 [label=AccumulateGrad]
	13582949472 -> 13582950096
	13583062560 [label="model.layer3.0.downsample.1.weight
 (256)" fillcolor=lightblue]
	13583062560 -> 13582949472
	13582949472 [label=AccumulateGrad]
	13582949568 -> 13582950096
	13583062960 [label="model.layer3.0.downsample.1.bias
 (256)" fillcolor=lightblue]
	13583062960 -> 13582949568
	13582949568 [label=AccumulateGrad]
	13582950384 -> 13582950816
	13583064320 [label="model.layer3.1.conv1.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	13583064320 -> 13582950384
	13582950384 [label=AccumulateGrad]
	13582950960 -> 13582951056
	13583064880 [label="model.layer3.1.bn1.weight
 (256)" fillcolor=lightblue]
	13583064880 -> 13582950960
	13582950960 [label=AccumulateGrad]
	13582951248 -> 13582951056
	13583065200 [label="model.layer3.1.bn1.bias
 (256)" fillcolor=lightblue]
	13583065200 -> 13582951248
	13582951248 [label=AccumulateGrad]
	13582951440 -> 13582951872
	13583066480 [label="model.layer3.1.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	13583066480 -> 13582951440
	13582951440 [label=AccumulateGrad]
	13582951968 -> 13582952160
	13583067040 [label="model.layer3.1.bn2.weight
 (256)" fillcolor=lightblue]
	13583067040 -> 13582951968
	13582951968 [label=AccumulateGrad]
	13582952064 -> 13582952160
	13583067360 [label="model.layer3.1.bn2.bias
 (256)" fillcolor=lightblue]
	13583067360 -> 13582952064
	13582952064 [label=AccumulateGrad]
	13582952304 -> 13582952400
	13582952784 -> 13582953120
	13583067840 [label="model.layer4.0.conv1.weight
 (512, 256, 3, 3)" fillcolor=lightblue]
	13583067840 -> 13582952784
	13582952784 [label=AccumulateGrad]
	13582953216 -> 13582953312
	13583069120 [label="model.layer4.0.bn1.weight
 (512)" fillcolor=lightblue]
	13583069120 -> 13582953216
	13582953216 [label=AccumulateGrad]
	13582953552 -> 13582953312
	13583069520 [label="model.layer4.0.bn1.bias
 (512)" fillcolor=lightblue]
	13583069520 -> 13582953552
	13582953552 [label=AccumulateGrad]
	13582953744 -> 13582954032
	13583070880 [label="model.layer4.0.conv2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	13583070880 -> 13582953744
	13582953744 [label=AccumulateGrad]
	13582954128 -> 13582954368
	13583071440 [label="model.layer4.0.bn2.weight
 (512)" fillcolor=lightblue]
	13583071440 -> 13582954128
	13582954128 [label=AccumulateGrad]
	13582954224 -> 13582954368
	13583071840 [label="model.layer4.0.bn2.bias
 (512)" fillcolor=lightblue]
	13583071840 -> 13582954224
	13582954224 [label=AccumulateGrad]
	13582954464 -> 13582954560
	13582954464 [label=NativeBatchNormBackward0]
	13582952880 -> 13582954464
	13582952880 [label=ConvolutionBackward0]
	13582952688 -> 13582952880
	13582952592 -> 13582952880
	13583073120 [label="model.layer4.0.downsample.0.weight
 (512, 256, 1, 1)" fillcolor=lightblue]
	13583073120 -> 13582952592
	13582952592 [label=AccumulateGrad]
	13582953840 -> 13582954464
	13583188432 [label="model.layer4.0.downsample.1.weight
 (512)" fillcolor=lightblue]
	13583188432 -> 13582953840
	13582953840 [label=AccumulateGrad]
	13582953936 -> 13582954464
	13583188752 [label="model.layer4.0.downsample.1.bias
 (512)" fillcolor=lightblue]
	13583188752 -> 13582953936
	13582953936 [label=AccumulateGrad]
	13582954800 -> 13582955184
	13583190032 [label="model.layer4.1.conv1.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	13583190032 -> 13582954800
	13582954800 [label=AccumulateGrad]
	13582955280 -> 13582955376
	13583190592 [label="model.layer4.1.bn1.weight
 (512)" fillcolor=lightblue]
	13583190592 -> 13582955280
	13582955280 [label=AccumulateGrad]
	13582955616 -> 13582955376
	13583190992 [label="model.layer4.1.bn1.bias
 (512)" fillcolor=lightblue]
	13583190992 -> 13582955616
	13582955616 [label=AccumulateGrad]
	13582955808 -> 13582956144
	13583192352 [label="model.layer4.1.conv2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	13583192352 -> 13582955808
	13582955808 [label=AccumulateGrad]
	13582956240 -> 13582956432
	13583192912 [label="model.layer4.1.bn2.weight
 (512)" fillcolor=lightblue]
	13583192912 -> 13582956240
	13582956240 [label=AccumulateGrad]
	13582956336 -> 13582956432
	13583193312 [label="model.layer4.1.bn2.bias
 (512)" fillcolor=lightblue]
	13583193312 -> 13582956336
	13582956336 [label=AccumulateGrad]
	13582956528 -> 13582956624
	13582957296 -> 13582957776
	13582957296 [label=TBackward0]
	13582956720 -> 13582957296
	13583194512 [label="model.fc.weight
 (2, 512)" fillcolor=lightblue]
	13583194512 -> 13582956720
	13582956720 [label=AccumulateGrad]
	13582957776 -> 13582911344
}
