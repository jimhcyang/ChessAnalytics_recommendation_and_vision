digraph {
	graph [size="59.55,59.55"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	6239864208 [label="
 (1, 2)" fillcolor=darkolivegreen1]
	15637951728 [label=AddmmBackward0]
	15637947936 -> 15637951728
	6240290912 [label="model.fc.bias
 (2)" fillcolor=lightblue]
	6240290912 -> 15637947936
	15637947936 [label=AccumulateGrad]
	15637953888 -> 15637951728
	15637953888 [label=ViewBackward0]
	15637950096 -> 15637953888
	15637950096 [label=MeanBackward1]
	15637950144 -> 15637950096
	15637950144 [label=ReluBackward0]
	15637953744 -> 15637950144
	15637953744 [label=AddBackward0]
	15637951008 -> 15637953744
	15637951008 [label=NativeBatchNormBackward0]
	15637952304 -> 15637951008
	15637952304 [label=ConvolutionBackward0]
	15637952976 -> 15637952304
	15637952976 [label=ReluBackward0]
	13723448464 -> 15637952976
	13723448464 [label=NativeBatchNormBackward0]
	13723449232 -> 13723448464
	13723449232 [label=ConvolutionBackward0]
	15637950864 -> 13723449232
	15637950864 [label=ReluBackward0]
	13723442128 -> 15637950864
	13723442128 [label=AddBackward0]
	13723440304 -> 13723442128
	13723440304 [label=NativeBatchNormBackward0]
	13723446256 -> 13723440304
	13723446256 [label=ConvolutionBackward0]
	13723437088 -> 13723446256
	13723437088 [label=ReluBackward0]
	13723440592 -> 13723437088
	13723440592 [label=NativeBatchNormBackward0]
	13723435504 -> 13723440592
	13723435504 [label=ConvolutionBackward0]
	13723438672 -> 13723435504
	13723438672 [label=ReluBackward0]
	13723440016 -> 13723438672
	13723440016 [label=AddBackward0]
	13723441984 -> 13723440016
	13723441984 [label=NativeBatchNormBackward0]
	13723438528 -> 13723441984
	13723438528 [label=ConvolutionBackward0]
	13723436752 -> 13723438528
	13723436752 [label=ReluBackward0]
	13723440496 -> 13723436752
	13723440496 [label=NativeBatchNormBackward0]
	13723439248 -> 13723440496
	13723439248 [label=ConvolutionBackward0]
	13723435120 -> 13723439248
	13723435120 [label=ReluBackward0]
	13723440112 -> 13723435120
	13723440112 [label=AddBackward0]
	13723438768 -> 13723440112
	13723438768 [label=NativeBatchNormBackward0]
	13723436032 -> 13723438768
	13723436032 [label=ConvolutionBackward0]
	13723436464 -> 13723436032
	13723436464 [label=ReluBackward0]
	13723648544 -> 13723436464
	13723648544 [label=NativeBatchNormBackward0]
	13723663328 -> 13723648544
	13723663328 [label=ConvolutionBackward0]
	13723656416 -> 13723663328
	13723656416 [label=ReluBackward0]
	13723652480 -> 13723656416
	13723652480 [label=AddBackward0]
	13723653536 -> 13723652480
	13723653536 [label=NativeBatchNormBackward0]
	13723658864 -> 13723653536
	13723658864 [label=ConvolutionBackward0]
	13723659920 -> 13723658864
	13723659920 [label=ReluBackward0]
	13723657760 -> 13723659920
	13723657760 [label=NativeBatchNormBackward0]
	13723660304 -> 13723657760
	13723660304 [label=ConvolutionBackward0]
	13723659728 -> 13723660304
	13723659728 [label=ReluBackward0]
	13723651664 -> 13723659728
	13723651664 [label=AddBackward0]
	13723663232 -> 13723651664
	13723663232 [label=NativeBatchNormBackward0]
	13723649552 -> 13723663232
	13723649552 [label=ConvolutionBackward0]
	13723657664 -> 13723649552
	13723657664 [label=ReluBackward0]
	13723648208 -> 13723657664
	13723648208 [label=NativeBatchNormBackward0]
	13723651088 -> 13723648208
	13723651088 [label=ConvolutionBackward0]
	4397544496 -> 13723651088
	4397544496 [label=ReluBackward0]
	13723056256 -> 4397544496
	13723056256 [label=AddBackward0]
	13723056688 -> 13723056256
	13723056688 [label=NativeBatchNormBackward0]
	13723057936 -> 13723056688
	13723057936 [label=ConvolutionBackward0]
	13723045984 -> 13723057936
	13723045984 [label=ReluBackward0]
	13723047568 -> 13723045984
	13723047568 [label=NativeBatchNormBackward0]
	13723056448 -> 13723047568
	13723056448 [label=ConvolutionBackward0]
	13723056880 -> 13723056448
	13723056880 [label=ReluBackward0]
	13723057696 -> 13723056880
	13723057696 [label=AddBackward0]
	13723047328 -> 13723057696
	13723047328 [label=NativeBatchNormBackward0]
	13723058032 -> 13723047328
	13723058032 [label=ConvolutionBackward0]
	13723277616 -> 13723058032
	13723277616 [label=ReluBackward0]
	13723273872 -> 13723277616
	13723273872 [label=NativeBatchNormBackward0]
	13582948656 -> 13723273872
	13582948656 [label=ConvolutionBackward0]
	13723056544 -> 13582948656
	13723056544 [label=MaxPool2DWithIndicesBackward0]
	13582947840 -> 13723056544
	13582947840 [label=ReluBackward0]
	13582946400 -> 13582947840
	13582946400 [label=NativeBatchNormBackward0]
	13582954176 -> 13582946400
	13582954176 [label=ConvolutionBackward0]
	13582956288 -> 13582954176
	13723104288 [label="model.conv1.weight
 (64, 3, 7, 7)" fillcolor=lightblue]
	13723104288 -> 13582956288
	13582956288 [label=AccumulateGrad]
	13582944336 -> 13582946400
	13723099328 [label="model.bn1.weight
 (64)" fillcolor=lightblue]
	13723099328 -> 13582944336
	13582944336 [label=AccumulateGrad]
	13582955136 -> 13582946400
	13723099088 [label="model.bn1.bias
 (64)" fillcolor=lightblue]
	13723099088 -> 13582955136
	13582955136 [label=AccumulateGrad]
	13582956048 -> 13582948656
	13723096048 [label="model.layer1.0.conv1.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	13723096048 -> 13582956048
	13582956048 [label=AccumulateGrad]
	13582944384 -> 13723273872
	13723107008 [label="model.layer1.0.bn1.weight
 (64)" fillcolor=lightblue]
	13723107008 -> 13582944384
	13582944384 [label=AccumulateGrad]
	13582954896 -> 13723273872
	13723094048 [label="model.layer1.0.bn1.bias
 (64)" fillcolor=lightblue]
	13723094048 -> 13582954896
	13582954896 [label=AccumulateGrad]
	13723274496 -> 13723058032
	13723104608 [label="model.layer1.0.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	13723104608 -> 13723274496
	13723274496 [label=AccumulateGrad]
	13723272720 -> 13723047328
	6240450448 [label="model.layer1.0.bn2.weight
 (64)" fillcolor=lightblue]
	6240450448 -> 13723272720
	13723272720 [label=AccumulateGrad]
	13723272528 -> 13723047328
	13723566224 [label="model.layer1.0.bn2.bias
 (64)" fillcolor=lightblue]
	13723566224 -> 13723272528
	13723272528 [label=AccumulateGrad]
	13723056544 -> 13723057696
	13723043968 -> 13723056448
	13723571184 [label="model.layer1.1.conv1.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	13723571184 -> 13723043968
	13723043968 [label=AccumulateGrad]
	13723048480 -> 13723047568
	13723581504 [label="model.layer1.1.bn1.weight
 (64)" fillcolor=lightblue]
	13723581504 -> 13723048480
	13723048480 [label=AccumulateGrad]
	13723057072 -> 13723047568
	13723580224 [label="model.layer1.1.bn1.bias
 (64)" fillcolor=lightblue]
	13723580224 -> 13723057072
	13723057072 [label=AccumulateGrad]
	13723050160 -> 13723057936
	13723567504 [label="model.layer1.1.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	13723567504 -> 13723050160
	13723050160 [label=AccumulateGrad]
	13723057360 -> 13723056688
	13723569264 [label="model.layer1.1.bn2.weight
 (64)" fillcolor=lightblue]
	13723569264 -> 13723057360
	13723057360 [label=AccumulateGrad]
	13723056352 -> 13723056688
	13723572544 [label="model.layer1.1.bn2.bias
 (64)" fillcolor=lightblue]
	13723572544 -> 13723056352
	13723056352 [label=AccumulateGrad]
	13723056880 -> 13723056256
	4397542576 -> 13723651088
	13723567344 [label="model.layer2.0.conv1.weight
 (128, 64, 3, 3)" fillcolor=lightblue]
	13723567344 -> 4397542576
	4397542576 [label=AccumulateGrad]
	13723657376 -> 13723648208
	13723578784 [label="model.layer2.0.bn1.weight
 (128)" fillcolor=lightblue]
	13723578784 -> 13723657376
	13723657376 [label=AccumulateGrad]
	4397542192 -> 13723648208
	13723569344 [label="model.layer2.0.bn1.bias
 (128)" fillcolor=lightblue]
	13723569344 -> 4397542192
	4397542192 [label=AccumulateGrad]
	13723648880 -> 13723649552
	13723570144 [label="model.layer2.0.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	13723570144 -> 13723648880
	13723648880 [label=AccumulateGrad]
	13723661552 -> 13723663232
	6240707552 [label="model.layer2.0.bn2.weight
 (128)" fillcolor=lightblue]
	6240707552 -> 13723661552
	13723661552 [label=AccumulateGrad]
	13723663472 -> 13723663232
	6240710112 [label="model.layer2.0.bn2.bias
 (128)" fillcolor=lightblue]
	6240710112 -> 13723663472
	13723663472 [label=AccumulateGrad]
	13723656224 -> 13723651664
	13723656224 [label=NativeBatchNormBackward0]
	4397539840 -> 13723656224
	4397539840 [label=ConvolutionBackward0]
	4397544496 -> 4397539840
	13723045216 -> 4397539840
	6240023584 [label="model.layer2.0.downsample.0.weight
 (128, 64, 1, 1)" fillcolor=lightblue]
	6240023584 -> 13723045216
	13723045216 [label=AccumulateGrad]
	13723649360 -> 13723656224
	6240026224 [label="model.layer2.0.downsample.1.weight
 (128)" fillcolor=lightblue]
	6240026224 -> 13723649360
	13723649360 [label=AccumulateGrad]
	13723648928 -> 13723656224
	6240025984 [label="model.layer2.0.downsample.1.bias
 (128)" fillcolor=lightblue]
	6240025984 -> 13723648928
	13723648928 [label=AccumulateGrad]
	13723661264 -> 13723660304
	6240024464 [label="model.layer2.1.conv1.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	6240024464 -> 13723661264
	13723661264 [label=AccumulateGrad]
	13723651520 -> 13723657760
	6240023504 [label="model.layer2.1.bn1.weight
 (128)" fillcolor=lightblue]
	6240023504 -> 13723651520
	13723651520 [label=AccumulateGrad]
	13723663568 -> 13723657760
	6240022944 [label="model.layer2.1.bn1.bias
 (128)" fillcolor=lightblue]
	6240022944 -> 13723663568
	13723663568 [label=AccumulateGrad]
	13723652768 -> 13723658864
	6240021104 [label="model.layer2.1.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	6240021104 -> 13723652768
	13723652768 [label=AccumulateGrad]
	13723661456 -> 13723653536
	6240016384 [label="model.layer2.1.bn2.weight
 (128)" fillcolor=lightblue]
	6240016384 -> 13723661456
	13723661456 [label=AccumulateGrad]
	13723657472 -> 13723653536
	6240011184 [label="model.layer2.1.bn2.bias
 (128)" fillcolor=lightblue]
	6240011184 -> 13723657472
	13723657472 [label=AccumulateGrad]
	13723659728 -> 13723652480
	13723662608 -> 13723663328
	6240015504 [label="model.layer3.0.conv1.weight
 (256, 128, 3, 3)" fillcolor=lightblue]
	6240015504 -> 13723662608
	13723662608 [label=AccumulateGrad]
	13723660736 -> 13723648544
	6240016944 [label="model.layer3.0.bn1.weight
 (256)" fillcolor=lightblue]
	6240016944 -> 13723660736
	13723660736 [label=AccumulateGrad]
	13723656752 -> 13723648544
	6240018544 [label="model.layer3.0.bn1.bias
 (256)" fillcolor=lightblue]
	6240018544 -> 13723656752
	13723656752 [label=AccumulateGrad]
	13723436368 -> 13723436032
	6240017744 [label="model.layer3.0.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	6240017744 -> 13723436368
	13723436368 [label=AccumulateGrad]
	13723440400 -> 13723438768
	6239715168 [label="model.layer3.0.bn2.weight
 (256)" fillcolor=lightblue]
	6239715168 -> 13723440400
	13723440400 [label=AccumulateGrad]
	13723435216 -> 13723438768
	6239714528 [label="model.layer3.0.bn2.bias
 (256)" fillcolor=lightblue]
	6239714528 -> 13723435216
	13723435216 [label=AccumulateGrad]
	13723438960 -> 13723440112
	13723438960 [label=NativeBatchNormBackward0]
	13723436176 -> 13723438960
	13723436176 [label=ConvolutionBackward0]
	13723656416 -> 13723436176
	13723653632 -> 13723436176
	6239700768 [label="model.layer3.0.downsample.0.weight
 (256, 128, 1, 1)" fillcolor=lightblue]
	6239700768 -> 13723653632
	13723653632 [label=AccumulateGrad]
	13723659104 -> 13723438960
	6239701808 [label="model.layer3.0.downsample.1.weight
 (256)" fillcolor=lightblue]
	6239701808 -> 13723659104
	13723659104 [label=AccumulateGrad]
	13723652624 -> 13723438960
	6239703568 [label="model.layer3.0.downsample.1.bias
 (256)" fillcolor=lightblue]
	6239703568 -> 13723652624
	13723652624 [label=AccumulateGrad]
	13723439488 -> 13723439248
	6239707488 [label="model.layer3.1.conv1.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	6239707488 -> 13723439488
	13723439488 [label=AccumulateGrad]
	13723437904 -> 13723440496
	6239708368 [label="model.layer3.1.bn1.weight
 (256)" fillcolor=lightblue]
	6239708368 -> 13723437904
	13723437904 [label=AccumulateGrad]
	13723440208 -> 13723440496
	6239709408 [label="model.layer3.1.bn1.bias
 (256)" fillcolor=lightblue]
	6239709408 -> 13723440208
	13723440208 [label=AccumulateGrad]
	13723437184 -> 13723438528
	6239714288 [label="model.layer3.1.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	6239714288 -> 13723437184
	13723437184 [label=AccumulateGrad]
	13723438336 -> 13723441984
	6239702848 [label="model.layer3.1.bn2.weight
 (256)" fillcolor=lightblue]
	6239702848 -> 13723438336
	13723438336 [label=AccumulateGrad]
	13723439152 -> 13723441984
	6239712208 [label="model.layer3.1.bn2.bias
 (256)" fillcolor=lightblue]
	6239712208 -> 13723439152
	13723439152 [label=AccumulateGrad]
	13723435120 -> 13723440016
	13723443088 -> 13723435504
	13958836560 [label="model.layer4.0.conv1.weight
 (512, 256, 3, 3)" fillcolor=lightblue]
	13958836560 -> 13723443088
	13723443088 [label=AccumulateGrad]
	13723441840 -> 13723440592
	6239874128 [label="model.layer4.0.bn1.weight
 (512)" fillcolor=lightblue]
	6239874128 -> 13723441840
	13723441840 [label=AccumulateGrad]
	13723445008 -> 13723440592
	6239865168 [label="model.layer4.0.bn1.bias
 (512)" fillcolor=lightblue]
	6239865168 -> 13723445008
	13723445008 [label=AccumulateGrad]
	13723448320 -> 13723446256
	6239873728 [label="model.layer4.0.conv2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	6239873728 -> 13723448320
	13723448320 [label=AccumulateGrad]
	13723435888 -> 13723440304
	6239863888 [label="model.layer4.0.bn2.weight
 (512)" fillcolor=lightblue]
	6239863888 -> 13723435888
	13723435888 [label=AccumulateGrad]
	13723451344 -> 13723440304
	6239864848 [label="model.layer4.0.bn2.bias
 (512)" fillcolor=lightblue]
	6239864848 -> 13723451344
	13723451344 [label=AccumulateGrad]
	13723440544 -> 13723442128
	13723440544 [label=NativeBatchNormBackward0]
	13723443520 -> 13723440544
	13723443520 [label=ConvolutionBackward0]
	13723438672 -> 13723443520
	13723437616 -> 13723443520
	6239868128 [label="model.layer4.0.downsample.0.weight
 (512, 256, 1, 1)" fillcolor=lightblue]
	6239868128 -> 13723437616
	13723437616 [label=AccumulateGrad]
	13723450000 -> 13723440544
	6239869168 [label="model.layer4.0.downsample.1.weight
 (512)" fillcolor=lightblue]
	6239869168 -> 13723450000
	13723450000 [label=AccumulateGrad]
	13723444672 -> 13723440544
	6239870768 [label="model.layer4.0.downsample.1.bias
 (512)" fillcolor=lightblue]
	6239870768 -> 13723444672
	13723444672 [label=AccumulateGrad]
	13723438864 -> 13723449232
	6239873888 [label="model.layer4.1.conv1.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	6239873888 -> 13723438864
	13723438864 [label=AccumulateGrad]
	13723447984 -> 13723448464
	6239874688 [label="model.layer4.1.bn1.weight
 (512)" fillcolor=lightblue]
	6239874688 -> 13723447984
	13723447984 [label=AccumulateGrad]
	13723450096 -> 13723448464
	6239876128 [label="model.layer4.1.bn1.bias
 (512)" fillcolor=lightblue]
	6239876128 -> 13723450096
	13723450096 [label=AccumulateGrad]
	15637953168 -> 15637952304
	6239870528 [label="model.layer4.1.conv2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	6239870528 -> 15637953168
	15637953168 [label=AccumulateGrad]
	15637948128 -> 15637951008
	6239867408 [label="model.layer4.1.bn2.weight
 (512)" fillcolor=lightblue]
	6239867408 -> 15637948128
	15637948128 [label=AccumulateGrad]
	15637954416 -> 15637951008
	15637542160 [label="model.layer4.1.bn2.bias
 (512)" fillcolor=lightblue]
	15637542160 -> 15637954416
	15637954416 [label=AccumulateGrad]
	15637950864 -> 15637953744
	15637950480 -> 15637951728
	15637950480 [label=TBackward0]
	15637954464 -> 15637950480
	6240293552 [label="model.fc.weight
 (2, 512)" fillcolor=lightblue]
	6240293552 -> 15637954464
	15637954464 [label=AccumulateGrad]
	15637951728 -> 6239864208
}
